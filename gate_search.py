import random
from funcs import gatePileMetaMakerMaker, allListsOfSizeX, simpleGateFuncMaker
from segmented_train import segmentedTrain, exhaustiveSearch, aggressiveSearch

def pront(x):
    print x

def generateRandomMatrix(n):
    return [[1*(random.random() < 0.5) for _ in range(n)] for _ in range(n)]

def generateRandomInput(n):
    return [1*(random.random() < 0.5) for _ in range(n)]

def generateZeroMatrix(n):
    return [[0 for _ in range(n)] for _ in range(n)]

# Careful! This is O(2^(2^n))
def generateAllTTs(n):
    allLists = allListsOfSizeX(n)

    allOutputs = allListsOfSizeX(2**n)

    functionSet = []

    for output in allOutputs:
        trainingSet = [[], []]
        testSet = [[], []]
        for i, l in enumerate(allLists):
            trainingSet[0].append(l)
            trainingSet[1].append(output[i])
            testSet[0].append(l)
            testSet[1].append(output[i])

        functionSet.append([trainingSet, testSet])

    return functionSet

# Takes a gate, and generates a random truth table involving it
# (Randomly sets parameters, and makes TT based on that)
def generateFuncMetaSetFromGate(n, gateMetaParamMatrix, numFuncs=1000, samplesPerFunc=1000):
    gatePileMaker = \
        gatePileMetaMakerMaker(n)(gateMetaParamMatrix)

    functionSet = []

    for _ in range(numFuncs):
        gatePileFunc = gatePileMaker(generateRandomMatrix(n))

        if samplesPerFunc == "all":
            functionSet.append(makeTrainingTestSetForAll(n, gatePileFunc))

        else:
            functionSet.append(makeRandomSampledTrainingTestSet(n, \
                gatePileFunc, samplesPerFunc))

    return functionSet

def generateRandomFuncMetaSetFromGates(n, numFuncs=1000, samplesPerFunc=1000):
    functionSet = []

    for _ in range(numFuncs):
        gatePileFunc = gatePileMetaMakerMaker(n)(randomGate(n))(generateRandomMatrix(n))

        if samplesPerFunc == "all":
            functionSet.append(makeTrainingTestSetForAll(n, gatePileFunc))

        else:
            functionSet.append(makeRandomSampledTrainingTestSet(n, \
                gatePileFunc, samplesPerFunc))

    return functionSet


def makeTrainingTestSetForAll(n, gatePileFunc):
    allInputs = allListsOfSizeX(n)

    trainingSet = [[], []]
    testSet = [[], []]

    for inp in allInputs:
        trainingSet[0].append(inp)
        testSet[0].append(inp)

        trainingSet[1].append(gatePileFunc(inp))
        testSet[1].append(gatePileFunc(inp))

    return [trainingSet, testSet]

def makeRandomSampledTrainingTestSet(n, gatePileFunc, numSamples):
    trainingSet = [[], []]
    testSet = [[], []]

    for _ in range(numSamples):
        inp = generateRandomInput(n)
        trainingSet[0].append(inp)
        trainingSet[1].append(gatePileFunc(inp))

    for _ in range(numSamples):
        inp = generateRandomInput(n)
        testSet[0].append(inp)
        testSet[1].append(gatePileFunc(inp))

    return [trainingSet, testSet]

def majorityGateMetaParamMatrix(n):
    return [[[1*(j+n-i-k>k+i-j) for k in range(n+1-i)] for j in range(i+1)] for i in range(n+1)]

def nandGateMetaParamMatrix(n):
    return [[[1*(i-j>0) for k in range(n+1-i)] for j in range(i+1)] for i in range(n+1)]

def goodAutoGeneratedGate(n):
    assert n == 3
    return [[[1, 0, 1, 0]], [[1, 0, 1], [1, 1, 0]], [[1, 0], [1, 1], [0, 1]], [[0], [0], [0], [1]]]

def majorityChallenger(n):
    assert n == 5
    return [[[0, 1, 0, 1, 0, 0]], [[1, 1, 0, 0, 0], [0, 1, 1, 0, 0]], \
        [[1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0]], [[1, 1, 0], [1, 0, 0], \
        [1, 1, 0], [1, 0, 0]], [[0, 0], [0, 0], [1, 0], [1, 1], [1, 1]], \
        [[0], [0], [0], [1], [1], [1]]]

def majorityChallenger2(n):
    assert n == 5
    return [[[1, 1, 1, 0, 0, 0]], [[1, 0, 0, 0, 0], [1, 1, 1, 1, 1]], \
        [[1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 0, 0]], [[0, 0, 0], [1, 0, 0], \
        [1, 1, 0], [1, 1, 1]], [[0, 0], [0, 0], [1, 0], [1, 1], [1, 1]], \
        [[0], [0], [0], [1], [1], [1]]]

def majorityChallenger3(n):
    assert n == 5
    return [[[1, 0, 1, 1, 0, 0]], [[1, 0, 0, 1, 0], [0, 1, 1, 1, 1]], \
        [[0, 1, 0, 0], [0, 1, 1, 0], [1, 1, 1, 1]], [[0, 1, 0], [1, 1, 0], \
        [1, 1, 1], [1, 1, 1]], [[1, 1], [1, 0], [1, 0], [1, 1], [1, 1]], \
        [[1], [1], [1], [1], [0], [0]]]

def randomGate(n):
    return [[[1*(random.random() < 0.5) for k in range(n+1-i)] for j in range(i+1)] for i in range(n+1)]

def simpleRandomGate(n):
    return [[1*(random.random() < 0.5) for _ in range(4)], \
        [1*(random.random() < 0.5) for _ in range(n+1)]]

def zeroGate(n):
    return [[[0 for k in range(n+1-i)] for j in range(i+1)] for i in range(n+1)]

def simpleZeroGate(n):
    return [[0 for _ in range(4)], [0 for _ in range(n+1)]]

def measureGateError(gatePileMaker, funcMetaSet):
    totalError = 0

    for i, funcSet in enumerate(funcMetaSet):

        totalError += trainAndTest(gatePileMaker, generateZeroMatrix(n), funcSet)

#        pront("Tested on " + str(i) + " / " + str(len(funcMetaSet)) + " functions.")

    return totalError/float(i+1)

def findBestGate(trainingMetaSet, dimension, gatePileMetaMaker, initialGateMetaParamMatrix):
    gateParamMatrix = initialGateMetaParamMatrix[:]

    pront("Initial gate guess: " + str(gateParamMatrix))

    segmentedTrain(gateParamMatrix, dimension, gatePileMetaMaker, trainingMetaSet, \
        measureGateError, True)

    return gateParamMatrix

def findBestGateAggressive(trainingMetaSet, dimension, gatePileMetaMaker, \
    initialGateMetaParamMatrix):

    gateParamMatrix = initialGateMetaParamMatrix[:]

    pront("Initial gate guess: " + str(gateParamMatrix))

    aggressiveSearch(gateParamMatrix, dimension, gatePileMetaMaker, trainingMetaSet, \
        measureGateError, True)

    return gateParamMatrix

def findBestGateExhaustive(trainingMetaSet, dimension, gatePileMetaMaker, \
    initialGateMetaParamMatrix):

    gateParamMatrix = initialGateMetaParamMatrix[:]

    pront("Initial gate guess: " + str(gateParamMatrix))

    exhaustiveSearch(gateParamMatrix, dimension, gatePileMetaMaker, trainingMetaSet, \
        measureGateError, True)

    return gateParamMatrix

def trainAndTest(gatePileMaker, initialParamMatrix, funcSet):
    trainingSet = funcSet[0]
    testSet = funcSet[1]
    paramMatrix = initialParamMatrix[:]
    segmentedTrain(paramMatrix, 2, gatePileMaker, trainingSet, measureFuncError)
    gatePileFunc = gatePileMaker(paramMatrix)
    error = test(gatePileFunc, testSet, measureFuncError)
    return error

def measureFuncError(func, dataSet):
    inputs = dataSet[0]
    outputs = dataSet[1]

    funcOutputs = [func(inp) for inp in inputs]

    funcError = sum([fo != o for fo, o in zip(funcOutputs, outputs)]) \
        / float(len(outputs))

    return funcError

def matrixWrite(matrix, indexList, newValue):
    if len(indexList) == 1:
        matrix[indexList[0]] = newValue

    else:
        matrixWrite(matrix[indexList[0]], indexList[1:], newValue)

def matrixRead(matrix, indexList):
    if len(indexList) == 1:
        return matrix[indexList[0]]

    else:
        return matrixRead(matrix[indexList[0]], indexList[1:])

# This function is general enough to be used at any level of meta-ness
# It's a segmented train
# It can handle any dimension
# WARNING: it will modify paramMatrix!
# Ugh this is too damn hard I'm gonna write the specific case
def trainTooGeneral(paramMatrix, indexList, funcToTrain, trainingObject, errorFunc):
    wasChangeAtSomePoint = True

    wasRecentChange = True
    while wasRecentChange:
        # We want to keep going till there's no more change, then we can stop

        if type(paramMatrix) == type([]):
            for subMatrixIndex, subMatrix in enumerate(paramMatrix):
                subMatrixModified, changeHappened = train(paramMatrix,
                    indexList+[subMatrixIndex], funcToTrain, trainingObject,
                        errorFunc)

                matrixWrite(paramMatrix, indexList, subMatrixModified)
                wasRecentChange = wasRecentChange or changeHappened

        elif type(paramMatrix) == type(0):
            return


def train2D(initialParamMatrix, funcToTrain, trainingObject, errorFunc):
    paramMatrix = initialParamMatrix

    wasChange = True
    while wasChange:
        wasChange = False

        for vectorIndex, vector in enumerate(paramMatrix):
            paramMatrix, vectorChanged = moveToBestNeighborVector(paramMatrix,
                funcToTrain, vectorIndex, trainingObject, errorFunc)
            wasChange = wasChange or vectorChanged

    return paramMatrix

def moveToBestNeighborVectorOld(originalParamMatrix, funcToTrain, vectorIndex,
    trainingObject, errorFunc):

    # Test the original's error
    originalFunc = funcToTrain(originalParamMatrix)
    originalError = errorFunc(originalFunc, trainingObject)

    # Check each of the neighbors to see if one has a better error
    modifiedParamMatrix = originalParamMatrix[:]
    modifiedParamMatrix[vectorIndex] = modifiedParamMatrix[vectorIndex][:]

    bestError = originalError
    bestIndex = None
    vectorChanged = False

    for i, elt in enumerate(originalParamMatrix[vectorIndex]):
        # Change the relevant element

        modifiedParamMatrix[vectorIndex][i] = 1-elt
        neighborFunc = funcToTrain(modifiedParamMatrix)
        neighborError = errorFunc(neighborFunc, trainingObject)

        if neighborError < bestError:
            bestError = neighborError
            bestIndex = i
            vectorChanged = True

        # change it back
        modifiedParamMatrix[vectorIndex][i] = elt

    if bestIndex != None:
        elt = modifiedParamMatrix[vectorIndex][bestIndex]
        modifiedParamMatrix[vectorIndex][bestIndex] = 1-elt

    return modifiedParamMatrix, vectorChanged

def test(gatePileFunc, testObject, errorFunc):
    return errorFunc(gatePileFunc, testObject)

def arrangeGateChallenge(n, challengerGate, defendingGate, numFuncs,
    samplesPerFunc):

    funcSet = generateFuncMetaSetFromGate(n, defendingGate, numFuncs, \
        samplesPerFunc)

    challengerGateError = measureGateError(gatePileMetaMakerMaker(n)(challengerGate), \
        funcSet)

    defendingGateError = measureGateError(gatePileMetaMakerMaker(n)(defendingGate), \
        funcSet)

    pront("Challenger gate: error of " + str(challengerGateError))
    pront("Defending gate: error of " + str(defendingGateError))

    if challengerGateError < defendingGateError:
        pront("Challenger wins!")

    elif challengerGateError > defendingGateError:
        pront("Defender wins!")

    else:
        pront("Tie match!")

def gateContest(n, gate1, gate2, numFuncs, samplesPerFunc):
    funcSet = generateRandomFuncMetaSetFromGates(n, numFuncs, samplesPerFunc)
    gate1Error = measureGateError(gatePileMetaMakerMaker(n)(gate1), funcSet)
    gate2Error = measureGateError(gatePileMetaMakerMaker(n)(gate2), funcSet)

    pront("Gate 1: error of " + str(gate1Error))
    pront("Gate 2: error of " + str(gate2Error))

    if gate1Error < gate2Error:
        pront("Gate 1 wins!")

    elif gate1Error > gate2Error:
        pront("Gate 2 wins!")

    else:
        pront("Tie match!")

#majorityGate = simpleGateFuncMaker(3, [[1,0,0,1], [0,0,1,1]])
#print majorityGate([0,1,1], [0,1,0])

#nandGate = simpleGateFuncMaker(3, [[1,1,0,1], [1,1,1,0]])
#print nandGate([1,0,0],[0,0,0])

n = 5

#print findBestGateExhaustive(generateAllTTs(n), 3, gatePileMetaMakerMaker(n, \
#    simpleGateFuncMaker), simpleZeroGate(n))

#n = 5

#goldenGate = majorityGateMetaParamMatrix(n)

#print arrangeGateChallenge(n, nandGateMetaParamMatrix(n), goldenGate, 1000,
#    "all")

#print gateContest(n, majorityChallenger3(n), majorityGateMetaParamMatrix(n), 1000, "all")

print findBestGateAggressive(generateRandomFuncMetaSetFromGates(n, \
    numFuncs=3000, samplesPerFunc="all"), 3, gatePileMetaMakerMaker(n), randomGate(n))

#print measureGateError(gatePileMetaMakerMaker(n)(nandGateMetaParamMatrix(n)), \
#    generateAllTTs(n))

#print findBestGateAggressive(generateAllTTs(n), gatePileMetaMakerMaker(n), \
#    randomGate(n))
